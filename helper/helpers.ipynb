{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert python txt <p1> <p2> file to json file format\n",
    "import json\n",
    "f = open(\"mapping_db_wk_clean.txt\",'r',encoding='utf-8').read()\n",
    "json_dict = {\"values\" : []}\n",
    "for line in f.split(\"\\n\"):\n",
    "    values = line.split(\" \")\n",
    "    if len(values) == 2 : db,wk = values\n",
    "    json_dict[\"values\"].append({\"db\" : db, \"wk\": wk})\n",
    "with open(\"mapping_db_wk.json\", \"w\") as outfile:\n",
    "    json.dump(json_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#compare sameAs prop with clean db prop\n",
    "with open('mapping_db_wk.json', 'r') as openfile:\n",
    "    mapping_dict = json.load(openfile)\n",
    "\n",
    "#load mapping into a dict to get constant acces time\n",
    "db_sameAs_dict = {}\n",
    "for i in mapping_dict[\"values\"]:\n",
    "    db_sameAs_dict[i[\"db\"]] = i[\"wk\"]\n",
    "\n",
    "with open(\"../data/property_support.json\") as json_file:\n",
    "        property_dictionnary = json.load(json_file)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter prop count dictionary with sameAs dictionary\n",
    "filtered_prop = {}\n",
    "for i in db_sameAs_dict.keys():\n",
    "    val = property_dictionnary.get(i)\n",
    "    if val: filtered_prop[i] = val\n",
    "\n",
    "#sort the dict\n",
    "prop = dict(sorted(filtered_prop.items(), key=lambda item: item[1], reverse=True))\n",
    "#keep only prop with support > 1000\n",
    "prop = dict(filter(lambda x,: True if x[1] > 1000 else False, prop.items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<http://www.wikidata.org/prop/P570>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_sameAs_dict['<http://dbpedia.org/ontology/deathDate>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http://www.wikidata.org/prop/P11143> sameAs <http://dbpedia.org/ontology/wikiPageID> : 1406259\n",
      "<http://www.wikidata.org/prop/P2451> sameAs <http://dbpedia.org/ontology/birthDate> : 471625\n",
      "<http://www.wikidata.org/prop/P570> sameAs <http://dbpedia.org/ontology/deathDate> : 170365\n",
      "<http://www.wikidata.org/prop/P2907> sameAs <http://dbpedia.org/ontology/utcOffset> : 163232\n",
      "<http://www.wikidata.org/prop/P6499> sameAs <http://dbpedia.org/ontology/populationTotal> : 154981\n",
      "<http://www.wikidata.org/prop/P8497> sameAs <http://dbpedia.org/ontology/Person/height> : 111006\n",
      "<http://www.wikidata.org/prop/P8483> sameAs <http://dbpedia.org/ontology/postalCode> : 106248\n",
      "<http://www.wikidata.org/prop/P5286> sameAs <http://dbpedia.org/ontology/runtime> : 97818\n",
      "<http://www.wikidata.org/prop/P1477> sameAs <http://dbpedia.org/ontology/originalName> : 70857\n",
      "<http://www.wikidata.org/prop/P10708> sameAs <http://dbpedia.org/ontology/areaCode> : 66970\n",
      "<http://www.wikidata.org/prop/P10673> sameAs <http://dbpedia.org/ontology/releaseDate> : 61238\n",
      "<http://www.wikidata.org/prop/P112> sameAs <http://dbpedia.org/ontology/foundingYear> : 50531\n",
      "<http://www.wikidata.org/prop/P11054> sameAs <http://dbpedia.org/ontology/number> : 43027\n",
      "<http://www.wikidata.org/prop/P10268> sameAs <http://dbpedia.org/ontology/imdbId> : 35122\n",
      "<http://www.wikidata.org/prop/P6833> sameAs <http://dbpedia.org/ontology/title> : 34916\n",
      "<http://www.wikidata.org/prop/P2918> sameAs <http://dbpedia.org/ontology/address> : 34716\n",
      "<http://www.wikidata.org/prop/P5974> sameAs <http://dbpedia.org/ontology/synonym> : 23916\n",
      "<http://www.wikidata.org/prop/P6000> sameAs <http://dbpedia.org/ontology/areaWater> : 23761\n",
      "<http://www.wikidata.org/prop/P1546> sameAs <http://dbpedia.org/ontology/motto> : 20162\n",
      "<http://www.wikidata.org/prop/P1113> sameAs <http://dbpedia.org/ontology/numberOfEpisodes> : 20030\n",
      "<http://www.wikidata.org/prop/P10673> sameAs <http://dbpedia.org/ontology/openingDate> : 19088\n",
      "<http://www.wikidata.org/prop/P112> sameAs <http://dbpedia.org/ontology/foundingDate> : 18463\n",
      "<http://www.wikidata.org/prop/P3423> sameAs <http://dbpedia.org/ontology/inseeCode> : 17796\n",
      "<http://www.wikidata.org/prop/P1104> sameAs <http://dbpedia.org/ontology/numberOfPages> : 14315\n",
      "<http://www.wikidata.org/prop/P7708> sameAs <http://dbpedia.org/ontology/isbn> : 13610\n",
      "<http://www.wikidata.org/prop/P2437> sameAs <http://dbpedia.org/ontology/numberOfSeasons> : 12890\n",
      "<http://www.wikidata.org/prop/P2769> sameAs <http://dbpedia.org/ontology/budget> : 12160\n",
      "<http://www.wikidata.org/prop/P6364> sameAs <http://dbpedia.org/ontology/officialSchoolColour> : 12074\n",
      "<http://www.wikidata.org/prop/P3415> sameAs <http://dbpedia.org/ontology/startDate> : 11738\n",
      "<http://www.wikidata.org/prop/P4970> sameAs <http://dbpedia.org/ontology/alternativeName> : 11150\n",
      "<http://www.wikidata.org/prop/P945> sameAs <http://dbpedia.org/ontology/allegiance> : 11028\n",
      "<http://www.wikidata.org/prop/P1671> sameAs <http://dbpedia.org/ontology/routeNumber> : 10895\n",
      "<http://www.wikidata.org/prop/P6510> sameAs <http://dbpedia.org/ontology/topSpeed> : 10703\n",
      "<http://www.wikidata.org/prop/P1836> sameAs <http://dbpedia.org/ontology/draftPick> : 10397\n",
      "<http://www.wikidata.org/prop/P8093> sameAs <http://dbpedia.org/ontology/oclc> : 10183\n",
      "<http://www.wikidata.org/prop/P735> sameAs <http://dbpedia.org/ontology/formerName> : 9883\n",
      "<http://www.wikidata.org/prop/P6639> sameAs <http://dbpedia.org/ontology/capacity> : 9236\n",
      "<http://www.wikidata.org/prop/P3460> sameAs <http://dbpedia.org/ontology/militaryCommand> : 8992\n",
      "<http://www.wikidata.org/prop/P8703> sameAs <http://dbpedia.org/ontology/abbreviation> : 8383\n",
      "<http://www.wikidata.org/prop/P5606> sameAs <http://dbpedia.org/ontology/broadcastStationClass> : 8280\n",
      "<http://www.wikidata.org/prop/P2545> sameAs <http://dbpedia.org/ontology/bowlingSide> : 7437\n",
      "<http://www.wikidata.org/prop/P2144> sameAs <http://dbpedia.org/ontology/frequency> : 7389\n",
      "<http://www.wikidata.org/prop/P10786> sameAs <http://dbpedia.org/ontology/formationDate> : 7230\n",
      "<http://www.wikidata.org/prop/P822> sameAs <http://dbpedia.org/ontology/mascot> : 6944\n",
      "<http://www.wikidata.org/prop/P4803> sameAs <http://dbpedia.org/ontology/agencyStationCode> : 6929\n",
      "<http://www.wikidata.org/prop/P11113> sameAs <http://dbpedia.org/ontology/facilityId> : 6900\n",
      "<http://www.wikidata.org/prop/P10215> sameAs <http://dbpedia.org/ontology/numberBuilt> : 6551\n",
      "<http://www.wikidata.org/prop/P5209> sameAs <http://dbpedia.org/ontology/isoCodeRegion> : 6411\n",
      "<http://www.wikidata.org/prop/P5677> sameAs <http://dbpedia.org/ontology/strength> : 6315\n",
      "<http://www.wikidata.org/prop/P3661> sameAs <http://dbpedia.org/ontology/managerTitle> : 5745\n",
      "<http://www.wikidata.org/prop/P7363> sameAs <http://dbpedia.org/ontology/issn> : 5642\n",
      "<http://www.wikidata.org/prop/P2262> sameAs <http://dbpedia.org/ontology/draft> : 5299\n",
      "<http://www.wikidata.org/prop/P5800> sameAs <http://dbpedia.org/ontology/role> : 5285\n",
      "<http://www.wikidata.org/prop/P3586> sameAs <http://dbpedia.org/ontology/iupacName> : 5268\n",
      "<http://www.wikidata.org/prop/P9860> sameAs <http://dbpedia.org/ontology/icaoLocationIdentifier> : 5127\n",
      "<http://www.wikidata.org/prop/P8887> sameAs <http://dbpedia.org/ontology/percentageOfAreaWater> : 5010\n",
      "<http://www.wikidata.org/prop/P7779> sameAs <http://dbpedia.org/ontology/militaryUnitSize> : 4670\n",
      "<http://www.wikidata.org/prop/P2660> sameAs <http://dbpedia.org/ontology/prominence> : 4539\n",
      "<http://www.wikidata.org/prop/P3337> sameAs <http://dbpedia.org/ontology/time> : 4354\n",
      "<http://www.wikidata.org/prop/P3931> sameAs <http://dbpedia.org/ontology/licensee> : 4156\n",
      "<http://www.wikidata.org/prop/P6852> sameAs <http://dbpedia.org/ontology/casNumber> : 3924\n",
      "<http://www.wikidata.org/prop/P8502> sameAs <http://dbpedia.org/ontology/floorCount> : 3912\n",
      "<http://www.wikidata.org/prop/P1923> sameAs <http://dbpedia.org/ontology/teamName> : 3635\n",
      "<http://www.wikidata.org/prop/P576> sameAs <http://dbpedia.org/ontology/dissolutionYear> : 3600\n",
      "<http://www.wikidata.org/prop/P627> sameAs <http://dbpedia.org/ontology/iucnCategory> : 3562\n",
      "<http://www.wikidata.org/prop/P8136> sameAs <http://dbpedia.org/ontology/lcc> : 3545\n",
      "<http://www.wikidata.org/prop/P6271> sameAs <http://dbpedia.org/ontology/demonym> : 3542\n",
      "<http://www.wikidata.org/prop/P3640> sameAs <http://dbpedia.org/ontology/fdaUniiCode> : 3521\n",
      "<http://www.wikidata.org/prop/P662> sameAs <http://dbpedia.org/ontology/pubchem> : 3484\n",
      "<http://www.wikidata.org/prop/P2197> sameAs <http://dbpedia.org/ontology/productionEndYear> : 3465\n",
      "<http://www.wikidata.org/prop/P2130> sameAs <http://dbpedia.org/ontology/cost> : 3316\n",
      "<http://www.wikidata.org/prop/P4584> sameAs <http://dbpedia.org/ontology/firstAppearance> : 3307\n",
      "<http://www.wikidata.org/prop/P10038> sameAs <http://dbpedia.org/ontology/identificationSymbol> : 3187\n",
      "<http://www.wikidata.org/prop/P7457> sameAs <http://dbpedia.org/ontology/signature> : 3130\n",
      "<http://www.wikidata.org/prop/P2121> sameAs <http://dbpedia.org/ontology/careerPrizeMoney> : 3130\n",
      "<http://www.wikidata.org/prop/P9255> sameAs <http://dbpedia.org/ontology/iso6393Code> : 3082\n",
      "<http://www.wikidata.org/prop/P8361> sameAs <http://dbpedia.org/ontology/dcc> : 2857\n",
      "<http://www.wikidata.org/prop/P7253> sameAs <http://dbpedia.org/ontology/colourName> : 2783\n",
      "<http://www.wikidata.org/prop/P10786> sameAs <http://dbpedia.org/ontology/acquirementDate> : 2747\n",
      "<http://www.wikidata.org/prop/P2295> sameAs <http://dbpedia.org/ontology/netIncome> : 2642\n",
      "<http://www.wikidata.org/prop/P2669> sameAs <http://dbpedia.org/ontology/dissolutionDate> : 2539\n",
      "<http://www.wikidata.org/prop/P3236> sameAs <http://dbpedia.org/ontology/publicationDate> : 2494\n",
      "<http://www.wikidata.org/prop/P7807> sameAs <http://dbpedia.org/ontology/icd10> : 2455\n",
      "<http://www.wikidata.org/prop/P6340> sameAs <http://dbpedia.org/ontology/ecNumber> : 2434\n",
      "<http://www.wikidata.org/prop/P4508> sameAs <http://dbpedia.org/ontology/bicycleInformation> : 2370\n",
      "<http://www.wikidata.org/prop/P11108> sameAs <http://dbpedia.org/ontology/participant> : 2368\n",
      "<http://www.wikidata.org/prop/P2049> sameAs <http://dbpedia.org/ontology/MeanOfTransportation/width> : 2357\n",
      "<http://www.wikidata.org/prop/P2227> sameAs <http://dbpedia.org/ontology/membership> : 2292\n",
      "<http://www.wikidata.org/prop/P9888> sameAs <http://dbpedia.org/ontology/conservationStatus> : 2246\n",
      "<http://www.wikidata.org/prop/P592> sameAs <http://dbpedia.org/ontology/chEMBL> : 2098\n",
      "<http://www.wikidata.org/prop/P2575> sameAs <http://dbpedia.org/ontology/numberOfVolumes> : 1994\n",
      "<http://www.wikidata.org/prop/P8811> sameAs <http://dbpedia.org/ontology/lccn> : 1968\n",
      "<http://www.wikidata.org/prop/P2146> sameAs <http://dbpedia.org/ontology/orbitalPeriod> : 1948\n",
      "<http://www.wikidata.org/prop/P1692> sameAs <http://dbpedia.org/ontology/icd9> : 1942\n",
      "<http://www.wikidata.org/prop/P575> sameAs <http://dbpedia.org/ontology/discovered> : 1934\n",
      "<http://www.wikidata.org/prop/P8627> sameAs <http://dbpedia.org/ontology/closingDate> : 1878\n",
      "<http://www.wikidata.org/prop/P4118> sameAs <http://dbpedia.org/ontology/faaLocationIdentifier> : 1814\n",
      "<http://www.wikidata.org/prop/P1449> sameAs <http://dbpedia.org/ontology/pseudonym> : 1795\n",
      "<http://www.wikidata.org/prop/P1884> sameAs <http://dbpedia.org/ontology/hairColor> : 1672\n",
      "<http://www.wikidata.org/prop/P6259> sameAs <http://dbpedia.org/ontology/epoch> : 1671\n",
      "<http://www.wikidata.org/prop/P1340> sameAs <http://dbpedia.org/ontology/eyeColor> : 1626\n",
      "<http://www.wikidata.org/prop/P9340> sameAs <http://dbpedia.org/ontology/meshId> : 1499\n",
      "<http://www.wikidata.org/prop/P699> sameAs <http://dbpedia.org/ontology/diseasesDB> : 1451\n",
      "<http://www.wikidata.org/prop/P10135> sameAs <http://dbpedia.org/ontology/recordDate> : 1444\n",
      "<http://www.wikidata.org/prop/P10246> sameAs <http://dbpedia.org/ontology/medlinePlus> : 1375\n",
      "<http://www.wikidata.org/prop/P610> sameAs <http://dbpedia.org/ontology/firstAscentYear> : 1368\n",
      "<http://www.wikidata.org/prop/P7124> sameAs <http://dbpedia.org/ontology/firstPublicationDate> : 1365\n",
      "<http://www.wikidata.org/prop/P5348> sameAs <http://dbpedia.org/ontology/diameter> : 1323\n",
      "<http://www.wikidata.org/prop/P10631> sameAs <http://dbpedia.org/ontology/municipalityCode> : 1307\n",
      "<http://www.wikidata.org/prop/P8811> sameAs <http://dbpedia.org/ontology/coden> : 1294\n",
      "<http://www.wikidata.org/prop/P247> sameAs <http://dbpedia.org/ontology/cosparId> : 1292\n",
      "<http://www.wikidata.org/prop/P715> sameAs <http://dbpedia.org/ontology/drugbank> : 1286\n",
      "<http://www.wikidata.org/prop/P2388> sameAs <http://dbpedia.org/ontology/office> : 1219\n",
      "<http://www.wikidata.org/prop/P10788> sameAs <http://dbpedia.org/ontology/serviceNumber> : 1212\n",
      "<http://www.wikidata.org/prop/P3301> sameAs <http://dbpedia.org/ontology/broadcastTranslator> : 1197\n",
      "<http://www.wikidata.org/prop/P5978> sameAs <http://dbpedia.org/ontology/classification> : 1165\n",
      "<http://www.wikidata.org/prop/P2234> sameAs <http://dbpedia.org/ontology/volume> : 1123\n",
      "<http://www.wikidata.org/prop/P9374> sameAs <http://dbpedia.org/ontology/omim> : 1102\n",
      "<http://www.wikidata.org/prop/P6224> sameAs <http://dbpedia.org/ontology/description> : 1083\n",
      "<http://www.wikidata.org/prop/P673> sameAs <http://dbpedia.org/ontology/eMedicineSubject> : 1071\n",
      "<http://www.wikidata.org/prop/P673> sameAs <http://dbpedia.org/ontology/eMedicineTopic> : 1069\n",
      "<http://www.wikidata.org/prop/P6801> sameAs <http://dbpedia.org/ontology/bedCount> : 1044\n",
      "<http://www.wikidata.org/prop/P8058> sameAs <http://dbpedia.org/ontology/symbol> : 1043\n",
      "<http://www.wikidata.org/prop/P683> sameAs <http://dbpedia.org/ontology/chEBI> : 1012\n"
     ]
    }
   ],
   "source": [
    "for i in prop.keys():\n",
    "        print(f\"{db_sameAs_dict[i]} sameAs {i} : {prop[i]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import \n",
    "import time\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#const\n",
    "DBPEDIA = \"http://dbpedia.org/sparql\"\n",
    "WIKIDATA = \"https://query.wikidata.org/sparql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isbn - wdt:P957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparql_query(query : str, endpoint : str ) -> dict:\n",
    "    sparql = SPARQLWrapper(\n",
    "        endpoint\n",
    "    )\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    sparql.setQuery(query)\n",
    "\n",
    "    try:\n",
    "        ret = sparql.queryAndConvert()\n",
    "        return ret\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise Exception(\"Error in query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_value_sample(prop : str) -> str:\n",
    "    query = \"\"\"\n",
    "                select ?e ?p ?v where {\n",
    "                    values ?p {\"\"\"+prop+\"\"\"}.\n",
    "                    ?e ?p ?v\n",
    "                } limit 100\n",
    "            \"\"\"\n",
    "    query = re.sub(r\"\\n|'\",\"\",query)\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find prop to query\n",
    "db_prop = \"<http://dbpedia.org/ontology/releaseDate>\"\n",
    "wk_prop = \"<http://www.wikidata.org/prop/statement/P10673>\"\n",
    "result_db = sparql_query(query_value_sample(db_prop),DBPEDIA)\n",
    "result_wk = sparql_query(query_value_sample(wk_prop),WIKIDATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_i = []\n",
    "for i,j in zip(result_db[\"results\"][\"bindings\"],result_wk[\"results\"][\"bindings\"]):\n",
    "    #print(i)\n",
    "    #print(i['v']['value'],j['v']['value'])\n",
    "    date_i.append(i['v']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2006-10-28',\n",
       " '2005-11-15',\n",
       " '1936-11-07',\n",
       " '1955-09-08',\n",
       " '1936-12-07',\n",
       " '1937-04-12',\n",
       " '1974-12-02',\n",
       " '1972-06-30',\n",
       " '1955-07-06',\n",
       " '2006-09-09',\n",
       " '2007-11-06',\n",
       " '2007-11-13',\n",
       " '2009-09-29',\n",
       " '2014-03-25',\n",
       " '2001-12-04',\n",
       " '2004-09-06',\n",
       " '2004-11-10',\n",
       " '2004-11-23',\n",
       " '2004-12-09',\n",
       " '2005-09-27',\n",
       " '2011-09-27',\n",
       " '2000-09-12',\n",
       " '1999-09-14',\n",
       " '2003-11-11',\n",
       " '2004-02-05',\n",
       " '2006-04-04',\n",
       " '2005-11-16',\n",
       " '2005-11-24',\n",
       " '2008-09-23',\n",
       " '2010-10-19',\n",
       " '2005-09-13',\n",
       " '2005-09-14',\n",
       " '2006-03-07',\n",
       " '2009-09-08',\n",
       " '2011-11-01',\n",
       " '2003-06-03',\n",
       " '1969-02-10',\n",
       " '2017-04-28',\n",
       " '2022-10-24',\n",
       " '2004-05-10',\n",
       " '2018-03-14',\n",
       " '2002-04-11',\n",
       " '2013-03-09',\n",
       " '2012-06-11',\n",
       " '1992-11-21',\n",
       " '2001-09-23',\n",
       " '2017-05-23']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/28/2006 - 28/10/2006\n",
      "11/15/2005 - 15/11/2005\n",
      "11/07/1936 - 07/11/1936\n",
      "09/08/1955 - 08/09/1955\n",
      "12/07/1936 - 07/12/1936\n",
      "04/12/1937 - 12/04/1937\n",
      "12/02/1974 - 02/12/1974\n",
      "06/30/1972 - 30/06/1972\n",
      "07/06/1955 - 06/07/1955\n",
      "09/09/2006 - 09/09/2006\n",
      "11/06/2007 - 06/11/2007\n",
      "11/13/2007 - 13/11/2007\n",
      "09/29/2009 - 29/09/2009\n",
      "03/25/2014 - 25/03/2014\n",
      "12/04/2001 - 04/12/2001\n",
      "09/06/2004 - 06/09/2004\n",
      "11/10/2004 - 10/11/2004\n",
      "11/23/2004 - 23/11/2004\n",
      "12/09/2004 - 09/12/2004\n",
      "09/27/2005 - 27/09/2005\n",
      "09/27/2011 - 27/09/2011\n",
      "09/12/2000 - 12/09/2000\n",
      "09/14/1999 - 14/09/1999\n",
      "11/11/2003 - 11/11/2003\n",
      "02/05/2004 - 05/02/2004\n",
      "04/04/2006 - 04/04/2006\n",
      "11/16/2005 - 16/11/2005\n",
      "11/24/2005 - 24/11/2005\n",
      "09/23/2008 - 23/09/2008\n",
      "10/19/2010 - 19/10/2010\n",
      "09/13/2005 - 13/09/2005\n",
      "09/14/2005 - 14/09/2005\n",
      "03/07/2006 - 07/03/2006\n",
      "09/08/2009 - 08/09/2009\n",
      "11/01/2011 - 01/11/2011\n",
      "06/03/2003 - 03/06/2003\n",
      "02/10/1969 - 10/02/1969\n",
      "04/28/2017 - 28/04/2017\n",
      "10/24/2022 - 24/10/2022\n",
      "05/10/2004 - 10/05/2004\n",
      "03/14/2018 - 14/03/2018\n",
      "04/11/2002 - 11/04/2002\n",
      "03/09/2013 - 09/03/2013\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dates = [\n",
    "    '2006-10-28', '2005-11-15', '1936-11-07', '1955-09-08', '1936-12-07',\n",
    "    '1937-04-12', '1974-12-02', '1972-06-30', '1955-07-06', '2006-09-09',\n",
    "    '2007-11-06', '2007-11-13', '2009-09-29', '2014-03-25', '2001-12-04',\n",
    "    '2004-09-06', '2004-11-10', '2004-11-23', '2004-12-09', '2005-09-27',\n",
    "    '2011-09-27', '2000-09-12', '1999-09-14', '2003-11-11', '2004-02-05',\n",
    "    '2006-04-04', '2005-11-16', '2005-11-24', '2008-09-23', '2010-10-19',\n",
    "    '2005-09-13', '2005-09-14', '2006-03-07', '2009-09-08', '2011-11-01',\n",
    "    '2003-06-03', '1969-02-10', '2017-04-28', '2022-10-24', '2004-05-10',\n",
    "    '2018-03-14', '2002-04-11', '2013-03-09'\n",
    "]\n",
    "\n",
    "american_dates = []\n",
    "european_dates = []\n",
    "\n",
    "for date_str in dates:\n",
    "    date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    american_date = date_obj.strftime('%m/%d/%Y')\n",
    "    american_dates.append(american_date)\n",
    "    european_date = date_obj.strftime('%d/%m/%Y')\n",
    "    european_dates.append(european_date)\n",
    "\n",
    "# Print the converted dates\n",
    "for a,e in zip(american_dates,european_dates):\n",
    "    print(a+\" - \"+e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../data/prop_releaseDate_support_db.ttl\",\"r\",encoding=\"utf-8\").read()\n",
    "for i in f.split(\"\\n\"):\n",
    "    e,p,v = i.split(\"\\t\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'510', '123', '789'}, {'lala\\n', 'lk\\n'}]\n"
     ]
    }
   ],
   "source": [
    "foo = [set() for i in range(2)]\n",
    "with open(\"toot.txt\",\"r\") as f:\n",
    "    for i in f.readlines():\n",
    "        ii = i.split(\"_\")\n",
    "        foo[0].add(ii[0])\n",
    "        foo[1].add(ii[1])\n",
    "print(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<http://dbpedia.org/prop/statement/P110>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =\"<http://dbpedia.org/prop/P110>\"\n",
    "\n",
    "\"/\".join((x:= a.split(\"/\"))[0:-1])+\"/statement/\"+x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from functools import reduce \n",
    "import ijson\n",
    "import json\n",
    "import os\n",
    "\n",
    "def property_list_cutting(l: list ,slice_size: int ) -> list[list[str]]:\n",
    "    \"\"\"From a list, return slice 2D with n sublist of size \"slice_size\"\n",
    "\n",
    "    Args:\n",
    "        l (_type_): huge 1D list\n",
    "        slice_size (_type_): 2D list composed of n \"slice_size\" list\n",
    "\n",
    "    Returns:\n",
    "        list : slice_size\n",
    "    \"\"\"\n",
    "    index = 0\n",
    "    sliced_list = []\n",
    "    if len(l) < slice_size: return l\n",
    "    while index<len(l):\n",
    "        sliced_list.append(l[index:index+slice_size])\n",
    "        index+=slice_size\n",
    "    return sliced_list\n",
    "\n",
    "def query_generate_VALUES(slice: list) -> str:\n",
    "    \"\"\"From a list return a string composed of all element of the list joined\n",
    "\n",
    "    Args:\n",
    "        slice (list): 1D list\n",
    "\n",
    "    Returns:\n",
    "        str : return a string of the type \" slice[0] slice[1] slice[2] ... \"\n",
    "    \"\"\"\n",
    "    func = lambda acc,x : acc+\" \"+str(x)\n",
    "    acc = \"\"\n",
    "    joined_string = reduce(func, slice, acc)\n",
    "    return joined_string\n",
    "\n",
    "#TODO\n",
    "def read_sameAs_file(file: str, var_names : list[str] = [\"DB\",\"WK\"]) -> tuple[set[str],set[str]]:\n",
    "    \"\"\"Generate a list of sameAs from Dbpedia and Wikidata\n",
    "    Args:\n",
    "        file (str): sameAs json file name\n",
    "    \"\"\"\n",
    "    f_read = open(file, 'r', encoding=\"UTF-8\")\n",
    "\n",
    "    first,second = var_names#refactor with var name header from json file\n",
    "\n",
    "    db_entity_list = set()\n",
    "    wk_entity_list = set()\n",
    "\n",
    "    for record in ijson.items(f_read, \"results.bindings.item\"):\n",
    "        db_entity_list.add(f'<{record[first][\"value\"]}>')\n",
    "        wk_entity_list.add(f'<{record[second][\"value\"]}>')\n",
    "\n",
    "    f_read.close()\n",
    "    return db_entity_list,wk_entity_list\n",
    "\n",
    "\n",
    "def read_ttl_file(file: str) -> tuple[list[str],list[str],list[str]]:\n",
    "    \"\"\"Generate a list entity property value from a ttl file\n",
    "    Args:\n",
    "        file (str): sameAs json file name\n",
    "    \"\"\"\n",
    "    f_read = open(file, 'r', encoding=\"UTF-8\").read()\n",
    "\n",
    "    entity = []\n",
    "    prop = []\n",
    "    value = []\n",
    "\n",
    "    for line in f_read.split(\"\\n\"):\n",
    "        _line = line.split(\"\\t\")\n",
    "        if len(_line) == 3:\n",
    "            e,p,v = _line\n",
    "            entity.append(e)\n",
    "            prop.append(p)\n",
    "            value.append(v)\n",
    "        \n",
    "    return entity,prop,value\n",
    "\n",
    "\n",
    "def read_result_file(file : str, output_file : str, prop_var_name : str) -> None:\n",
    "    \"\"\"Read a result file to fill a dictionary \n",
    "\n",
    "    Args:\n",
    "        file (str): result file in json format\n",
    "    \"\"\"\n",
    "    \n",
    "    f_read = open(file, 'r', encoding=\"UTF-8\")\n",
    "    prop = prop_var_name #name of the sparql var\n",
    "    properties_count_file = output_file #dict file name\n",
    "    #if file exist open json file and load \n",
    "    if os.path.exists(properties_count_file):\n",
    "        with open(properties_count_file) as json_file:\n",
    "            property_dictionnary = json.load(json_file)\n",
    "            \n",
    "    #else start with empty dict\n",
    "    else:\n",
    "        property_dictionnary = {}\n",
    "\n",
    "    for record in ijson.items(f_read, \"results.bindings.item\"):\n",
    "        item = (f'<{record[prop][\"value\"]}>')\n",
    "        prop_count = property_dictionnary.get(item)\n",
    "        if prop_count: property_dictionnary[item] += 1\n",
    "        else: property_dictionnary[item] = 1\n",
    "\n",
    "    f_read.close()\n",
    "    #dump new dict\n",
    "    with open(properties_count_file, \"w\") as fp:\n",
    "        json.dump(property_dictionnary,fp) \n",
    "\n",
    "def sparql_call(sparql_query: str, result_file : str, database_name : str = \"dbpedia\") -> int :\n",
    "    \"\"\"Call a jar file to execute a sparql query on a database for a specified query \n",
    "\n",
    "    Args:\n",
    "        sparql_query (str): sparql query we want to execute on a database\n",
    "    \"\"\"\n",
    "    jar_path = \"~/../soulard/QueryHDT/SparqlToJSON.jar\"\n",
    "    database_path = {\n",
    "        \"dbpedia\" : \"~/../soulard/Graphs_HDT/DBpedia/DBpedia_en.hdt\",\n",
    "        \"wikidata\" : \"~/../soulard/Graphs_HDT/Wikidata/Wikidata_final.hdt\" \n",
    "    }\n",
    "    dataset_path = database_path[database_name]\n",
    "    #hdt_command = \"nohup java -Xmx120G -Xms120G -jar \"+jar_path+\" \"+dataset_path+\" \\\"\"+sparql_query+\"\\\" > \"+result_file+\" &\"\n",
    "    hdt_command = \"java -jar \"+jar_path+\" \"+dataset_path+\" \\\"\"+sparql_query+\"\\\" > \"+result_file\n",
    "    return os.system(hdt_command)\n",
    "\n",
    "def clean_nohup_file(result_file : str) -> None:\n",
    "    \"\"\"Commands to remove unwanted string at the start of nohup resulting files\n",
    "\n",
    "    Args:\n",
    "        result_file (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    code = 0\n",
    "    new_res_file = result_file.split(\".\")[0]+\"_clean.json\"\n",
    "    code += os.system(\"cp \"+result_file+\" \"+new_res_file)\n",
    "    code += os.system(\"awk 'NR > 3 { print }' < \"+new_res_file+\" > \"+result_file) #remove first 3 lines of the file\n",
    "    return code\n",
    "\n",
    "def concat_result_files(result_file : str, output_file : str, var_names : list) -> None:\n",
    "    \"\"\"Concat the json file to the output file\n",
    "\n",
    "    Args:\n",
    "        result_file (str): json file \n",
    "        output_file (str): ttl format file, append at the end of file\n",
    "    \"\"\"\n",
    "    \n",
    "    e,p,v = var_names\n",
    "    f_read = open(result_file, 'r', encoding=\"UTF-8\")\n",
    "    f_write = open(output_file, 'a', encoding=\"UTF-8\")\n",
    "    for record in ijson.items(f_read, \"results.bindings.item\"):\n",
    "        entity = (f'<{record[e][\"value\"]}>')\n",
    "        prop = (f'<{record[p][\"value\"]}>')\n",
    "        value = (f'{record[v][\"value\"]}')\n",
    "        f_write.write(entity+\"\\t\"+prop+\"\\t\"+value+\"\\n\")\n",
    "        \n",
    "    f_read.close()\n",
    "    f_write.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
